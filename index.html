<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Nikolaos Tziortziotis</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="owwwlab.com">



    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="A theme for faculty profile page" />
    <meta name="keywords" content="faculty profile, theme,css, html, jquery, transition, transform, 3d, css3" />

    <link rel="shortcut icon" href="http://owwwlab.com/favicon.ico">

    <!--CSS styles-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">  
    <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
    <link rel="stylesheet" href="css/magnific-popup.css">
    <link rel="stylesheet" href="css/style.css">
    <link id="theme-style" rel="stylesheet" href="css/styles/default.css">

    
    <!--/CSS styles-->
    <!--Javascript files-->
    <script type="text/javascript" src="js/jquery-1.10.2.js"></script>
    <script type="text/javascript" src="js/TweenMax.min.js"></script>
    <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
    <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>
    
    <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
    <script type="text/javascript" src="js/jquery.dropdownit.js"></script>

    <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
    <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>

    <script type="text/javascript" src="js/bootstrap.min.js"></script>

    <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>

    <script type="text/javascript" src="js/masonry.min.js"></script>

    <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>

    <script type="text/javascript" src="js/magnific-popup.js"></script>
    <script type="text/javascript" src="js/custom.js"></script>

    <!--/Javascript files-->


    <!--Custom Styles for demo only-->
    <link rel="stylesheet" href="custom-style.css">
    <script type="text/javascript" src="custom-style.js"></script>
    <!--/Custom Styles-->

  </head>
  <body>

    <div id="wrapper">
      <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a>

      <div id="sidebar">
        <div id="main-nav">
          <div id="nav-container">
            <div id="profile" class="clearfix">
              <div class="portrate hidden-xs"></div>
              <div class="title">
                <h2>Nikolaos Tziortziotis</h2>
		<!-- <h3>Department of Computer Science & Engineering <br> University of Ioannina</h3> -->
              </div>
              
            </div>
            <ul id="navigation">
              <li>
                <a href="#biography">
                  <div class="icon icon-user"></div>
                  <div class="text">About Me</div>
                </a>
              </li>  
              
              <li>
                <a href="#publications">
                  <div class="icon icon-edit"></div>
                  <div class="text">Publications</div>
                </a>
              </li> 
              <li>
                <a href="#teaching">
                  <div class="icon icon-time"></div>
                  <div class="text">Teaching</div>
                </a>
              </li> 
              
              <li>
                <a href="#research">
                  <div class="icon icon-book"></div>
                  <div class="text">Research</div>
                </a>
              </li> 
              
              <!--  <li>
                    <a href="#teaching">
                      <div class="icon icon-time"></div>
                      <div class="text">Teaching</div>
                    </a>
              </li>

              <li>
                <a href="#gallery">
                  <div class="icon icon-picture"></div>
                  <div class="text">Gallery</div>
                </a>
              </li>-->

	      <li>
                <a href="#usefullink">
                  <div class="icon icon-link"></div>
                  <div class="text">Useful Links</div>
                </a>
              </li>
              <li>
                <a href="#contact">
                  <div class="icon icon-calendar"></div>
                  <div class="text">Contact Me</div>
                </a>
              </li>

              <li class="external">
                <a href="CV\CV_Tziortziotis.pdf">
                  <div class="icon icon-download-alt"></div>
                  <div class="text">Download CV</div>
                </a>
              </li>
            </ul>
          </div>        
        </div>
        
        <div class="social-icons">
          <ul>
            <li><a href="https://www.facebook.com/nikos.tziortziotis.5?ref=fs"><i class="icon-facebook"></i></a></li>
            <li><a href="#"><i class="icon-twitter"></i></a></li>
            <li><a href="https://gr.linkedin.com/pub/tziortziotis-nikolaos/43/401/604"><i class="icon-linkedin"></i></a></li>
          </ul>
        </div>    
      </div>

      <div id="main">
        
        <div id="biography" class="page home" data-pos="home">
          <div class="pageheader">
            <div class="headercontent">
              <div class="section-container">
                
                <div class="row">
                  
                  <h3 class="title">Bio</h3>
                  <h2>My Name is Nikolaos Tziortziotis, </h2>
		  <p align="justify"> and currently I am a Data Scientist R&D at <a href="http://tradelab.com/en/">Tradelab</a> Programmatic platform. Right before that, I was a Postdoctoral researcher in the LaHDAK team of <a href=https://www.lri.fr/>LRI</a> at Université Paris-Sud, Paris, France (Nov - Dec 2018).  I was also a Postdoctoral researcher at the Data Science and Mining (<a href="http://www.lix.polytechnique.fr/dascim/">DaSciM</a>) group, <a href="http://www.lix.polytechnique.fr/en/">Computer Science Laboratory (LIX)</a>, Ecole Polytechnique, Paris, France (Nov 2015 - Oct 2018). I received my PhD from the <a href="http://www.cs.uoi.gr/en/index.php?menu=m1#">Department of Computer Science & Engineering</a> of <a href="http://www.uoi.gr/en/">University of Ioannina</a> in Greece. <!-- under the supervision of &nbsp<a href="http://www.cs.uoi.gr/~kblekas/">Prof. Konstantinos D. Blekas</a>-->
		    I received my MSc and BSc degrees from the same institution, in 2010 and 2007, respectively. My research interests include Reinforcement Learning, Decision Making under Uncertainty, Machine Learning, Artificial Intelligence and Robotics. </p>
                </div>
              </div>        
            </div>
          </div>

          <div class="pagecontents">
	    <div class="section color-2">
	      <div class="section-container">
                <div class="row">
                  <div class="col-md-12">
		    <div class="title">
                      <h3>News</h3>
                    </div>
                    <ul class="timeline">
		       <li class="open">
                        <div class="date">13-01-2019</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>PC Member at KDD and ECML-PKDD 2019</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
                              I will be on the program committee of AAAI 2019!
                            </div>
                          </div>
                        </div>
                      </li>
               <li class="open">	
                        <div class="date">30-07-2018</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>Two papers accepted at European Workshop of Reinforcement Learning</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
                              Two papers have been accepted for presentation at EWRL'18 (Lille, France, October 2018), entitled: i) Randomised Bayesian Least-Squares Policy Iteration, \w C. Dimitrakakis, and M. Vazirgiannis, and ii)  Reinforcement learning for supply chain optimisation, \w L. Kemmer, H. Kleist, D. Rochebouët, and J. Read.
                            </div>
                          </div>
                      </li>
		      <li class="open">	
                        <div class="date">19-07-2018</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>Paper accepted at Pattern Analysis & Applications Journal</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
                              Our paper with Jesse Read and Michalis Vazirgiannis entitled “Error-space Representations for Multi-dimensional Data-Streams with Temporal Dependence" has been accepted for publication in Pattern Analysis and Applications journal!
                            </div>
                          </div>
                      </li>
		      <li class="open">
                        <div class="date">21-06-2018</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>PC Member at AAAI 2019</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
                              I will be on the program committee of AAAI 2019!
                            </div>
                          </div>
                        </div>
                      </li>
		      <li class="open">
                        <div class="date">18-06-2017</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>Paper accepted at ASONAM 2018</h4></div>
                          <div class="text row open" style="display: block;">
			    <div class="col-md-10">Our paper with G. Salha and M. Vazirgiannis, "Adaptive Submodular Influence Maximization with Myopic Feedback" has been accepted for publication at ASONAM 2018.</div>
                          </div>
                        </div>
                      </li>
		      <li class="open">
                        <div class="date">20-02-2018</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>PC Member at ECML-PKDD 2018</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
                              I will be on the program committee of ECML-PKDD 2018!
                            </div>
                          </div>
                        </div>
                      </li>	
		      <li class="open">
                        <div class="date">22-06-2017</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>Paper accepted at ECML-PKDD 2017</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">Our paper with C. Dimitrakakis, " Bayesian Inference for Least Squares Temporal Difference Regularization" has been accepted for oral and poster presentation at ECML 2017.</div>
                          </div>
                        </div>
                      </li>


                      <li class="open">
                        <div class="date">05-05-2017</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>NVidia GPU Grant</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">My NVIDIA GPU Grant request has been approved. NVidia Corporation is going to support my research with the donation of a Titan XPascal GPU.</div>
                          </div>
                        </div>
                      </li>

                      <li class="open">
                        <div class="date">30-01-2017</div>
                        <div class="circle"></div>
                        <div class="data">
                          <div><h4>PC Member at ECML-PKDD,IJCAI, and AAAI 2017</h4></div>
                          <div class="text row open" style="display: block;">
                            <div class="col-md-10">
			      I will be on the program committee of ECML-PKDD, IJCAI and AAAI 2017!
                            </div>
                          </div>
                        </div>
                      </li>
                    </ul>
                    </div>
                    </div>
                  </div>
                </div>
		<div class="section color-1">
		  <div class="section-container">
                    <div class="row">
                      <div class="col-md-12">
			<div class="title text-left">
			  <h3>Education & Training</h3>
			</div>
			<ul class="ul-card">
			  <li>
                            <div class="dy">
                              <span class="degree">PhD</span>
                              <span class="year">2010-2015</span>
                            </div>
                            <div class="description">
                              <p class="waht">PhD in Computer Science & Engineering <br> PhD Thesis: Machine Learning for Intelligent Agents </p>
                              <p class="where">Department of Computer Science & Engineering, University of Ioannina</p>
                            </div>
			  </li>
			  <li>
                            <div class="dy">
                              <span class="degree">MSc</span>
			      <span class="year">2008-2010</span>
                            </div>
                            <div class="description">
                              <p class="waht">Master in Computer Science <br> MSc Thesis: Autonomous Mobile Robot Navigation using Reinforcement Learning</p>
                              <p class="where">Department of Computer Science, University of Ioannina</p>
                            </div>
			  </li>
			  <li>
                            <div class="dy">
                              <span class="degree">BSc</span>
			      <span class="year">2002-2007</span>
                            </div>
                            <div class="description">
                              <p class="waht">Bachelor in Computer Science</p>
                              <p class="where">Department of Computer Science, University of Ioannina</p>
                            </div>
			  </li>
			</ul>
                      </div>    
                    </div>    
		  </div>            
		</div>                        
              </div>
            </div> 

            <div id="research" class="page">
              <div class="pageheader">

		<div class="headercontent">

		  <div class="section-container">
                    <h2 class="title">Research Interests</h2>
                    
                    <div class="row">
                      <div class="col-md-4">
			<!--  <div class="subtitle text-center">
                              <h3>Interests</h3>
			</div> -->
			<ul class="ul-boxed list-unstyled">
			  <li>Reinforcement learning</li>
			  <li>Decision making under uncertainty</li>
			  <li>Machine learning</li>
			  <li>Community Detection</li>	
			  <li>Influence Maximization on Social Networks</li>
			</ul>
                      </div>
                    </div>
		  </div>
		</div>
              </div>
	    </div>
            <div id="teaching" class="page">
              <div class="pageheader">

		<div class="headercontent">

		  <div class="section-container">
                    <h2 class="title">Teaching</h2>
                    
                    <div class="row">
                      <div class="col-md-12">
			<!--  <div class="subtitle text-center">
                              <h3>Interests</h3>
			</div> -->
			<ul class="ul-boxed list-unstyled">
			  <li><strong>Machine Learning I</strong>, 2017-2019. M1. École Polytechnique, Université Paris Saclay.</li>
			  <li><strong>Advanced Topics in Artificial Intelligence</strong>, 2017-2018. M1. École Polytechnique, Université Paris Saclay.</li>
			  <li><strong>Methods for Big Data Analytics</strong>, 2016-2017. M2 Datascience Program. École Polytechnique, Université Paris Saclay.</li>
			  <li><strong>Introduction to Machine Learning</strong>, 2016-2017. M1. École Polytechnique, Université Paris Saclay.</li>
			  <li><strong>Data Science - Learning from Data</strong>, 2015-2016. M1. École Polytechnique, Université Paris Saclay.</li>
			</ul>
                      </div>
                    </div>
		  </div>
		</div>
              </div>
	    </div>


            <div id="publications" class="page">
              <div class="page-container">
		<div class="pageheader">
		  <div class="headercontent">
                    <div class="section-container">
                      
                      <h2 class="title">Publications</h2>
                      <!--     <div class="row">
                               <div class="col-md-12">
				 <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
                               </div>
                      </div> -->
                      
                    </div>
		  </div>
		</div>

		<div class="pagecontents">
		  
		  <div class="section color-1" id="filters">
                    <div class="section-container">
                      <div class="row">
			
			<div class="col-md-3">
			  <h3>Filter by type:</h3>
			</div>
			<div class="col-md-6">
			  <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                            <option class="filter" value="all" selected>All types</option>
                            <option class="filter" value="jpaper">Jounal Papers</option>
                            <option class="filter" value="mpaper">Magazine Papers</option>
                            <option class="filter" value="cpaper">Conference Papers</option>
			    <option class="filter" value="thesis">Thesis</option>
                            <!--          <option class="filter" value="bookchapter">Book Chapters</option>
					  <option class="filter" value="book">Books</option>
                            <option class="filter" value="report">Reports</option>
                            <option class="filter" value="tpaper">Technical Papers</option> -->
			  </select>
			</div>
			
			<div class="col-md-3" id="sort">
			  <span>Sort by year:</span>
			  <div class="btn-group pull-right"> 

                            <button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default"><i class="icon-sort-by-order"></i></button>
                            <button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default"><i class="icon-sort-by-order-alt"></i></button>
			  </div>
			</div>    
                      </div>
                    </div>
		  </div>

		  <div class="section color-2" id="pub-grid">
                    <div class="section-container">
                      
                      <div class="row">
			<div class="col-md-12">
			  <div class="pitems">


			    <div class="item mix cpaper" data-year="2018">
                              <div class="pubmain">
                                <div class="pubassets">

                                  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
                                  </a>
                                  <a href="http://noisy-text.github.io/2018/" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
                                  </a>
                                  <a href="http://noisy-text.github.io/2018/pdf/W-NUT201813.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
                                  </a>
				  <a href="posters/OMPTC_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>
                                </div>

                                <h4 class="pubtitle">Orthogonal Matching Pursuit for Text Classification</h4>
                                <div class="pubauthor">K. Skianis, <strong>N. Tziortziotis</strong>, and M. Vazirgiannis</div>
                                <div class="pubcite"><span class="label label-primary">Conference Paper</span> 4th Workshop on Noisy User-generated Text (W-NUT) at (EMNLP 2018), Brussels, Belgium, November 2018.<br> </div>

                              </div>
                              <div class="pubdetails">
                                <!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>In text classification, the problem of overfitting arises due to the high dimensionality, making regularization essential. Although classic regularizers provide sparsity, they fail to return highly accurate models. On the contrary, state-of-the-art group-lasso regularizers provide better results at the expense of low sparsity. In this paper, we apply a greedy variable selection algorithm, called Orthogonal Matching Pursuit, for the text classification task. We also extend standard Group OMP by introducing overlapping group OMP to handle overlapping groups of features. Empirical analysis verifies that both OMP and overlapping GOMP constitute powerful regularizers, able to produce effective and very sparse models.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2018">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://ewrl.wordpress.com/ewrl14-2018/#accepted" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://ewrl.files.wordpress.com/2018/09/ewrl_14_2018_paper_46.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  <a href="posters/RBLSPI_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>

				</div>

				<h4 class="pubtitle">Randomised Bayesian Least-Squares Policy Iteration</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  C. Dimitrakakis, and M. Vazirgiannis</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 14th European Workshop on Reinforcement Learning (EWRL 2018), Lille, France, October 2018.<br> </div>

                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> We introduce Bayesian least-squares policy iteration (BLSPI), an off-policy, model-free, policy iteration algorithm that uses the Bayesian least-squares temporal-difference (BLSTD) learning algorithm to evaluate policies. An online variant of BLSPI has been also proposed, called randomised BLSPI (RBLSPI), that improves its policy based on an incomplete policy evaluation step. In online setting, the exploration-exploitation dilemma should be addressed as we try to discover the optimal policy by using samples collected by ourselves. RBLSPI exploits the advantage of BLSTD to quantify our uncertainty about the value function. Inspired by Thompson sampling, RBLSPI first samples a value function from a posterior distribution over value functions, and then selects actions based on the sampled value function. The effectiveness and the exploration abilities of RBLSPI are demonstrated experimentally in several environments.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2018">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://ewrl.wordpress.com/ewrl14-2018/#accepted" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://ewrl.files.wordpress.com/2018/09/ewrl_14_2018_paper_44.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  <a href="posters/SCHAIN_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>
				</div>

				<h4 class="pubtitle">Reinforcement learning for supply chain optimization</h4>
				<div class="pubauthor"> Lukas Kemmer, Henrik von Kleist, Diego María De Grimaudet De Rochebouët,  <strong>N. Tziortziotis</strong> and Jesse Read</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 14th European Workshop on Reinforcement Learning (EWRL 2018), Lille, France, October 2018.<br> </div>

                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>In this paper we investigate the performance of two reinforcement learning (RL) agents within a supply chain optimization environment. We model the environment as a Markov decision process (MDP) where during each step it needs to be decided how many products should be produced in a factory and how many products should be shipped to different warehouses. We then design three different agents based on a static (ς, Q)-policy, the approximate SARSA and the REINFORCE algorithm. Here we pay special attention to different feature mapping functions that are used to model the value of state and stateaction pairs respectively. By testing the agents in different environment initializations, we find that both the approximate SARSA and the REINFORCE algorithms can outperform the static (ς, Q) agent in simple scenarios and that the REINFORCE agent performs best even in more complex settings.</p>
                              </div>
                            </div>
			    
			    
			    <div class="item mix jpaper" data-year="2018">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206318" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0206318&type=printable" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">MATI: An Efficient Algorithm for Influence Maximization in Social Networks</h4>
				<div class="pubauthor">M. G. Rossi, B. Shi, <strong>N. Tziortziotis</strong>, F.D. Malliaros, C. Giatsidis, and M. Vazirgiannis </div>
				<div class="pubcite"><span class="label label-success">Journal Paper</span> PLOS One, 13(11), 2018</div>
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> Influence maximization has attracted a lot of attention due to its numerous applications, including diffusion of social movements, the spread of news, viral marketing and outbreak of diseases. The objective is to discover a group of users that are able to maximize the spread of influence across a network. The greedy algorithm gives a solution to the Influence Maximization problem while having a good approximation ratio. Nevertheless it does not scale well for large scale datasets. In this paper, we propose Matrix Influence, MATI, an efficient algorithm that can be used under both the Linear Threshold and Independent Cascade diffusion models. MATI is based on the precalculation of the influence by taking advantage of the simple paths in the node’s neighborhood. An extensive empirical analysis has been performed on multiple real-world datasets showing that MATI has competitive performance when compared to other well-known algorithms with regards to running time and expected influence spread. </p>
                              </div>
                            </div>
			    
			    <div class="item mix jpaper" data-year="2018">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://link.springer.com/article/10.1007/s10044-018-0739-7?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&utm_source=ArticleAuthorContributingOnlineFirst&utm_medium=email&utm_content=AA_en_06082018&ArticleAuthorContributingOnlineFirst_20180802" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://link.springer.com/content/pdf/10.1007%2Fs10044-018-0739-7.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">Error-space representations for multi-dimensional data streams with temporal dependence</h4>
				<div class="pubauthor">J. Read, <strong>N. Tziortziotis</strong>,  M. Vazirgiannis</div>
				<div class="pubcite"><span class="label label-success">Journal Paper</span> Pattern Analysis and Applications (PAA), 2018.</div>
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> In many application scenarios data points are not only temporally dependent, but also expected in the form of a fast-moving stream. A broad selection of efficient learning algorithms exist which may be applied to data streams, but they typically do not take into account the temporal nature of the data. We motivate and design a method which creates an efficient representation of a data stream, where temporal information is embedded into each instance via the error space of forecasting models. Unlike many other methods in the literature, our approach can be rapidly initialized and does not require iterations over the full data sequence, thus it is suitable for a streaming scenario. This allows the application of off-the-shelf data-stream methods, depending on the application domain. In this paper we investigate classification. We compare to a large variety of methods (auto-encoders, HMMs, basis functions, clustering methodologies, and PCA) and find that our proposed methods performs very competitively, and offers much promise for future work. </p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2018">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://ieeexplore.ieee.org/document/8508254" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://arxiv.org/pdf/1704.06905.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">Adaptive Submodular Influence Maximization with Myopic Feedback</h4>
				<div class="pubauthor">G. Salha*, <strong>N. Tziortziotis</strong>*,  M. Vazirgiannis</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 10th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2018), Barcelona, France, August 2018.<br> ∗ These authors contributed equally to this work. </div>

                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> This paper examines the problem of adaptive influence maximization in social networks. As adaptive decision making is a time-critical task, a realistic feedback model has been considered, called myopic. In this direction, we propose the myopic adaptive greedy policy that is guaranteed to provide a (1 - 1/e)-approximation of the optimal policy under a variant of the independent cascade diffusion model. This strategy maximizes an alternative utility function that has been proven to be adaptive monotone and adaptive submodular. The proposed utility function considers the cumulative number of active nodes through the time, instead of the total number of the active nodes at the end of the diffusion. Our empirical analysis on real-world social networks reveals the benefits of the proposed myopic strategy, validating our theoretical results. </p>
                              </div>
                            </div>

          		    <div class="item mix cpaper" data-year="2017">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://link.springer.com/chapter/10.1007/978-3-319-71246-8_8" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://hal.inria.fr/hal-01593212/file/BLSTD.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				   <a href="posters/BLSTD_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>
				</div>

				<h4 class="pubtitle"> Bayesian Inference for Least Squares Temporal Difference Regularization</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  C. Dimitrakakis </div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 27th European Conference on Machine Learning Learning (ECML 2017), Skopje, September 2017.  </div>
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>This paper proposes a fully Bayesian approach for Least-Squares Temporal Differences (LSTD), resulting in fully probabilistic inference of value functions that avoids the overfitting commonly experienced with classical LSTD when the number of features is larger than the number of samples. Sparse Bayesian learning provides an elegant solution through the introduction of a prior over value function parameters. This gives us the advantages of probabilistic predictions, a sparse model, and good generalisation capabilities, as irrelevant parameters are marginalised out. The algorithm efficiently approximates the posterior distribution through variational inference. We demonstrate the ability of the algorithm in avoiding overfitting experimentally.</p>
                              </div>
                            </div>
			    
			    <div class="item mix cpaper" data-year="2017">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://hal-centralesupelec.archives-ouvertes.fr/hal-01672970" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://hal-centralesupelec.archives-ouvertes.fr/hal-01672970/document" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle"> MATI: An Efficient Algorithm for Influence Maximization in Social Networks</h4>
				<div class="pubauthor">M. G. Rossi, B. Shi, <strong>N. Tziortziotis</strong>, F.D. Malliaros, C. Giatsidis, and M. Vazirgiannis </div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 6th International Conference on Complex Networks and their Applications (Complex Networks 2017), Lyon, France, November 2017.</div>
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>In this study, we propose MATI, an efficient IM algorithm under both the LT and IC models. By taking advantage of the possible paths that are created in each node’s neighborhood, we have designed an algorithm that succeeds in locating the users that can maximize the influence in a social network while also being scalable for large datasets. In order to limit the computation of the possible paths and the respective probabilities of them being “active”, we use a pruning threshold θ that reduces the running time but also the accuracy of the influence computation. Extensive experiments show that MATI has competitive performance when compared with the baseline methods both in terms of influence and computation time. </p>
                              </div>
                            </div>
			    
  			    <div class="item mix jpaper" data-year="2016">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://arxiv.org/abs/1607.02096" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="https://arxiv.org/pdf/1607.02096.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">A k-core Decomposition Framework for Graph Clustering</h4>
				<div class="pubauthor">C. Giatsidis, F. D. Malliaros, <strong>N. Tziortziotis</strong>, C. Dhanjal, E. Kiagias, D. M. Thilikos, M. Vazirgiannis</div>
				<div class="pubcite"><span class="label label-success">Journal Paper</span> CoRR, 2016.</div>
                              </div>
                              <div class="pubdetails">
				<h4>Abstract</h4>
				<p>Graph clustering or community detection constitutes an important task for investigating the internal structure of graphs, with a plethora of applications in several domains. Traditional techniques for graph clustering, such as spectral methods, typically suffer from high time and space complexity. In this article, we present CoreCluster, an efficient graph clustering framework based on the concept of graph degeneracy, that can be used along with any known graph clustering algorithm. Our approach capitalizes on processing the graph in an hierarchical manner provided by its core expansion sequence, an ordered partition of the graph into different levels according to the k-core decomposition. Such a partition provides an efficient way to process the graph in an incremental manner that preserves its clustering structure, while making the execution of the chosen clustering algorithm much faster due to the smaller size of the graph's partitions onto which the algorithm operates. An experimental analysis on a multitude of real and synthetic data demonstrates that our approach can be applied to any clustering algorithm accelerating the clustering process, while the quality of the clustering structure is preserved or even improved.</p>
                              </div>
                            </div>


			    <div class="item mix jpaper" data-year="2016">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://ieeexplore.ieee.org/document/7307161/" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7307161" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">A Bayesian Ensemble Regression Framework on the Angry Birds Game</h4>
				<div class="pubauthor"><strong> N. Tziortziotis </strong>, G. Papagiannis, K. Blekas</div>
				<div class="pubcite"><span class="label label-success">Journal Paper</span> IEEE Transactions on Computational Intelligence and AI in Games (TCIAIG), 8(2):104-115, 2016</div>
                              </div>
                              <div class="pubdetails">
				<h4>Abstract</h4>
				<p>In this article we introduce AngryBER, an intelligent agent architecture on the Angry Birds domain that employs a Bayesian ensemble inference mechanism to promote decision making abilities. It is based on an efficient tree-like structure for encoding and representing game screenshots, where it exploits its enhanced modeling capabilities. This has the advantage to establish an informative feature space and translate the task of game playing into a regression analysis problem. A Bayesian ensemble regression framework is presented by considering that every combination of objects’ material and bird type has its own regression model. We address the problem of action selection as a multi-armed bandit problem, where the Upper Confidence Bound (UCB) strategy has been used. An efficient online learning procedure has been also developed for training the regression models. We have evaluated the proposed methodology on several game levels, and compared its performance with published results of all agents that participated in the 2013 and 2014 Angry Birds AI competitions. The superiority of the new method is readily deduced by inspecting the reported results.</p>
                              </div>
                            </div>
			    
			    <div class="item mix thesis" data-year="2015">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://www.cs.uoi.gr/tech_reports//publications/PD-2015-4.pdf" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/PhDThesisTziortziotis.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				</div>

				<h4 class="pubtitle">Machine Learning for Intelligent Agents</h4>
				<div class="pubauthor"><strong> N. Tziortziotis </strong></div>
				<div class="pubcite"><span class="label label-info">PhD Thesis</span> Department of Computer Science & Engineering, University of Ioannina, Greece, March 2015</div>	
			      </div>	
                              <div class="pubdetails">	
				<h4>Abstract</h4>
				<p>This dissertation studies the problem of developing intelligent agents, which are able to acquire skills in an autonomous way, simulating human behaviour. An autonomous intelligent agent acts e ectively in an unknown environment, directing its activity to- wards achieving a specific goal based on some performance measure. Through this interaction, a rich amount of information is received, which allows the agent to per- ceive the consequences of its actions, identify important behavioural components, and adapt its behaviour through learning. In this direction, the present dissertation con- cerns the development, implementation and evaluation of machine learning techniques for building intelligent agents. Three important and very challenging tasks are consid- ered: i) approximate reinforcement learning, where the agent’s policy is evaluated and improved through the approximation of the value function, ii) Bayesian reinforcement learning, where the reinforcement learning problem is modeled as a decision-theoretic problem, by placing a prior distribution over Markov Decision Processes (MDPs) that encodes the agent’s belief about the true environment, and iii) Development of intel- ligent agents on games, which constitute a really challenging platform for developing machine learning methodologies, involving a number of issues that should be resolved, such as the appropriate choice of state representation, continuous action spaces, etc..</p>
                              </div>
                            </div>	

			    <div class="item mix cpaper" data-year="2015">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://spie.org/Publications/Proceedings/Paper/10.1117/12.2077243" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/SPIE15.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Quality Optimization of H.264/AVC Video Transmission over Noisy Environments Using a Sparse Regression Framework</h4>
				<div class="pubauthor">K. Pandremmenou, <strong> N. Tziortziotis </strong>, S. Paluri, W. Zhang, K. Blekas, L. P. Kondi, S. Kumar</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> Visual Information Processing and Communication VI, Proceedings of SPIE-IS&T Electronic Imaging, San Francisco, CA, February 2015.</div>
				
                              </div>
                              <div class="pubdetails">
				<h4>Abstract</h4>
				<p>We propose the use of the Least Absolute Shrinkage and Selection Operator (LASSO) regression method in order to predict the Cumulative Mean Squared Error (CMSE), incurred by the loss of individual slices in video transmission. We extract a number of quality-relevant features from the H.264/AVC video sequences, which are given as input to the LASSO. This method has the benefit of not only keeping a subset of the features that have the strongest effects towards video quality, but also produces accurate CMSE predictions. Particularly, we study the LASSO regression through two different architectures; the Global LASSO (G.LASSO) and Local LASSO (L.LASSO). In G.LASSO, a single regression model is trained for all slice types together, while in L.LASSO, motivated by the fact that the values for some features are closely dependent on the considered slice type, each slice type has its own regression model, in an effort to improve LASSO’s prediction capability. Based on the predicted CMSE values, we group the video slices into four priority classes. Additionally, we consider a video transmission scenario over a noisy channel, where Unequal Error Protection (UEP) is applied to all prioritized slices. The provided results demonstrate the efficiency of LASSO in estimating CMSE with high accuracy, using only a few features.</p>
                              </div>
                            </div>
                            <div class="item mix jpaper" data-year="2014">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://jmlr.org/papers/v15/tziortziotis14a.html" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="http://jmlr.org/papers/volume15/tziortziotis14a/tziortziotis14a.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Cover Tree Bayesian Reinforcement Learning</h4>
				<div class="pubauthor"><strong> N. Tziortziotis </strong>, C. Dimitrakakis, K. Blekas</div>
				<div class="pubcite"><span class="label label-success">Journal Paper</span> Journal of Machine Learning Reaserch (JMLR), (15):2313-2335, 2014</div>
				
                              </div>
                              <div class="pubdetails">
				<h4>Abstract</h4>
				<p>This paper proposes an online tree-based Bayesian approach for reinforcement learning. For inference, we employ a generalised context tree model. This defines a distribution on multivariate Gaussian piecewise-linear models, which can be updated in closed form. The tree structure itself is constructed using the cover tree method, which remains efficient in high dimensional spaces. We combine the model with Thompson sampling and approximate dynamic programming to obtain effective exploration policies in unknown environments. The flexibility and computational simplicity of the model render it suitable for many reinforcement learning problems in continuous state spaces. We demonstrate this in an experimental comparison with a Gaussian process model, a linear model and simple least squares policy iteration.</p>
                              </div>
                            </div>

			    <div class="item mix mpaper" data-year="2014">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://www.aaai.org/ojs/index.php/aimagazine/article/view/2548" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <!--                         <a href="#" class="tooltips" title="Download" target="_blank">
                                                               <i class="icon-cloud-download"></i>
				  </a>
				  -->                     
				</div>

				<h4 class="pubtitle">The Reinforcement Learning Competition</h4>
				<div class="pubauthor">C. Dimitrakakis, G. Li, <strong> N. Tziortziotis </strong></div>
				<div class="pubcite"><span class="label label-warning">Magazine Paper</span> Artificial Intelligence (AI) Magazine, 2014</div>
				
                              </div>
                              <div class="pubdetails">
				<h4>Abstract</h4>
				<p>Reinforcement learning is one of the most general problems in artificial intelligence. It has been used to model problems in automated experiment design, control, economics, game playing, scheduling and telecommunications. The aim of the reinforcement learning competition is to encourage the development of very general learning agents for arbitrary reinforcement learning problems and to provide a test-bed for the unbiased evaluation of algorithms.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2014">
                              <div class="pubmain">
				<div class="pubassets">

				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>

				</div>

				<h4 class="pubtitle">Usable ABC Reinforcement Learning</h4>
				<div class="pubauthor">C. Dimitrakakis, <strong>N. Tziortziotis</strong></div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> Advances in Neural Information Processing Systems 27 (NIPS 2014), ABC in Montreal workshop, Montreal, Canada, December
				  2014 </div>

                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>The issues with the use of Approximate Bayesian Computation in Reinforcement Learning is the following. Firstly, that the model set may comprise simulators which are purely deterministic. Secondly, that there is a dependence between the policy used and the data collected, which necessitate maintaining a representation of the policy used as well as the data history. Thirdly, there is the question of the statistics used. Finally, there is the problem selecting a policy given the data observed so far. In this paper, we report some progress on using more sophisticated statistics and policy search algorithms and show that they have significant impact.
				</p>
                              </div>
                            </div>

                            <div class="item mix cpaper" data-year="2014">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://arxiv.org/abs/1408.5265" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="http://arxiv.org/pdf/1408.5265v2.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  <a href="posters/AngryBER_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>
				</div>

				<h4 class="pubtitle">A Bayesian Ensemble Regression Framework on the Angry Birds Game</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  G. Papagiannis, K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> ECAI Symposium on Artificial Intelligence in Angry Birds, Prague, Czech Republic, August 2014. <br> <strong>Second Place on the the Angry Birds AI Competiton 2014.</strong> </div>
				
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>An ensemble inference mechanism is proposed on the Angry Birds domain. It is based on an efficient tree structure for encoding and representing game screenshots, where it exploits its enhanced modeling capability. This has the advantage to establish an informative feature space and modify the task of game playing to a regression analysis problem. To this direction, we assume that each type of object material and bird pair has its own Bayesian linear regression model. In this way, a multi-model regression framework is designed that simultaneously calculates the conditional expectations of several objects and makes a target decision through an ensemble of regression models. The learning procedure is performed according to an online estimation strategy for the model parameters. We provide comparative experimental results on several game levels that empirically illustrate the efficiency of the proposed methodology.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2014">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07064-3_6#" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/SETN14.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Play Ms. Pac-Man using an Advanced Reinforcement Learning Agent</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>, K. Tziortziotis and K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>  8th Hellenic Conference on Artificial Intelligence (SETN 2014), Ioannina, Greece, May 2014.</div>
				
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> Reinforcement Learning (RL) algorithms have been promising methods for designing intelligent agents in games. Although their capability of learning in real time has been already proved, the high dimensionality of state spaces in most game domains can be seen as a significant barrier. This paper studies the popular arcade video game Ms. Pac-Man and outlines an approach to deal with its large dynamical environment. Our motivation is to demonstrate that an abstract but informative state space description plays a key role in the design of efficient RL agents. Thus, we can speed up the learning process without the necessity of Q-function approximation. Several experiments were made using the multiagent MASON platform where we measured the ability of the approach to reach optimum generic policies which enhances its generalization abilities.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2013">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://jmlr.org/proceedings/papers/v28/dimitrakakis13.html" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="http://jmlr.org/proceedings/papers/v28/dimitrakakis13.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">ABC Reinforcement Learning</h4>
				<div class="pubauthor">C. Dimitrakakis, <strong>N. Tziortziotis</strong></div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>30th International Conference on Machine Learning Learning (ICML 2013), Atlanta, USA, June 2013, JMLR W & CP 28(3):684-692.</div>
				
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> We introduce a simple, general framework for likelihood-free Bayesian reinforcement learning, through Approximate Bayesian Computation (ABC). The advantage is that we only require a prior distribution on a class of simulators. This is useful when a probabilistic model of the underlying process is too complex to formulate, but where detailed simulation models are available. ABC-RL allows the use of any Bayesian reinforcement learning technique in this case. It can be seen as an extension of simulation methods to both planning and inference. We experimentally demonstrate the potential of this approach in a comparison with LSPI. Finally, we introduce a theorem showing that ABC is sound.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2013">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://www.ijcai.org/Proceedings/13/Abstracts/255.html" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="http://www.ijcai.org/Proceedings/13/Papers/255.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  <a href="posters/LBRL_Poster.pdf" class="tooltips" title="" target="_blank" data-original-title="Download poster">
                                    <i class="fa fa-file-powerpoint-o"></i>
				  </a>
				</div>

				<h4 class="pubtitle">Linear Bayesian Reinforcement Learning</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>, C. Dimitrakakis, K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>23rd International Joint Conference on Artificial Intelligence (IJCAI 2013), Beijing, China, August 2013.</div>
				
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p>  This paper proposes a simple linear Bayesian approach to reinforcement learning. We show that with an appropriate basis, a Bayesian linear Gaussian model is sufficient for accurately estimating the system dynamics, and in particular when we allow for correlated noise. Policies are estimated by first sampling a transition model from the current posterior, and then performing approximate dynamic programming on the sampled model. This form of approximate Thompson sampling results in good exploration in unknown environments. The approach can also be seen as a Bayesian generalisation of least-squares policy iteration, where the empirical transition matrix is replaced with a sample from the posterior.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2013">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://ieeexplore.ieee.org/xpl/abstractKeywords.jsp?arnumber=6622817" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/DSP13.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Resource Allocation in Visual Sensor Networks Using a Reinforcement Learning Framework</h4>
				<div class="pubauthor">K. Pandremmenou, <strong>N. Tziortziotis</strong>, L. P. Kondi, K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>18th IEEE International Conference on Digital Signal Processing (DSP), Santorini, Greece, July 2013.</div>
				
                              </div>
                              <div class="pubdetails">
				<!--  <img alt="image" src="http://placehold.it/150x200"  style="padding:0 30px 30px 0;">-->
				<p> In recent years, video delivery over wireless visual sensor networks (VSNs) has gained increasing attention. The lossy compression and channel errors that occur during wireless multimedia transmissions can degrade the quality of the transmitted video sequences. This paper addresses the problem of cross-layer resource allocation among the nodes of a wireless direct-sequence code division multiple access (DS-CDMA) VSN. The optimal group of pictures (GoP) length during the encoding process is also considered, based on the motion level of each video sequence. Three optimization criteria that optimize a different objective function of the video qualities of the nodes are used. The nodes' transmission parameters, i.e., the source coding rates, channel coding rates and power levels can only take discrete values. In order to tackle the resulting optimization problem, a reinforcement learning (RL) strategy that promises efficient exploration and exploitation of the parameters' space is employed. This makes the proposed methodology usable in large or continuous state spaces as well as in an online mode. Experimental results highlight the efficiency of the proposed method.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2012">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6495113&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6495113" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/ICTAI12.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Model-based Reinforcement learning using online clustering</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>24th IEEE International Conference onTools with Artificial Intelligence (ICTAI 2012), Pireus, Greece, November 2012. </div>

				
                              </div>
                              <div class="pubdetails">
				<p> A significant issue in representing reinforcement learning agents in Markov decision processes is how to design efficient feature spaces in order to estimate optimal policy. This particular study addresses this challenge by proposing a compact framework that employs an on-line clustering approach for constructing appropriate basis functions. Also, it performs a state-action trajectory analysis to gain valuable affinity information among clusters and estimate their transition dynamics. Value function approximation is used for policy evaluation in a least-squares temporal difference framework. The proposed method is evaluated in several simulated and real environments, where we took promising results.</p>
                              </div>
                            </div>
			    
			    <div class="item mix cpaper" data-year="2012">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://link.springer.com/chapter/10.1007%2F978-3-642-30448-4_23" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/SETN12.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">An online kernel-based clustering approach for value function approximation</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 7th Hellenic Conference on Artificial Intelligence (SETN 2012), Lamia, Greece, May 2012.</div>

				
                              </div>
                              <div class="pubdetails">
				<p> Value function approximation is a critical task in solving Markov decision processes and accurately modeling reinforcement learning agents. A significant issue is how to construct efficient feature spaces from samples collected by the environment in order to obtain an optimal policy. The particular study addresses this challenge by proposing an on-line kernel-based clustering approach for building appropriate basis functions during the learning process. The method uses a kernel function capable of handling pairs of state-action as sequentially generated by the agent. At each time step, the procedure either adds a new cluster, or adjusts the winning cluster’s parameters. By considering the value function as a linear combination of the constructed basis functions, the weights are optimized in a temporal-difference framework in order to minimize the Bellman approximation error. The proposed method is evaluated in numerous known simulated environments.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2011">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="http://link.springer.com/chapter/10.1007%2F978-3-642-29946-9_15" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/ewrl11.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">Value Function Approximation through Sparse Bayesian Modeling</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span>  9th European Workshop on Reinforcement Learning (EWRL-9), Athens, Greece, September 2011.</div>
				
			      </div>
                              <div class="pubdetails">
				<p>  In this study we present a sparse Bayesian framework for value function approximation. The proposed method is based on the on-line construction of a dictionary of states which are collected during the exploration of the environment by the agent. A linear regression model is established for the observed partial discounted return of such dictionary states, where we employ the Relevance Vector Machine (RVM) and exploit its enhanced modeling capability due to the embedded sparsity properties. In order to speed-up the optimization procedure and allow dealing with large-scale problems, an incremental strategy is adopted. A number of experiments have been conducted on both simulated and real environments, where we took promising results in comparison with another Bayesian approach that uses Gaussian processes.</p>
                              </div>
                            </div>

			    <div class="item mix cpaper" data-year="2011">
                              <div class="pubmain">
				<div class="pubassets">
				  
				  <a href="#" class="pubcollapse">
                                    <i class="icon-expand-alt"></i>
				  </a>
				  <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3436" class="tooltips" title="External link" target="_blank">
                                    <i class="icon-external-link"></i>
				  </a>
				  <a href="pubs/AAAI11.pdf" class="tooltips" title="Download" target="_blank">
                                    <i class="icon-cloud-download"></i>
				  </a>
				  
				</div>

				<h4 class="pubtitle">A Bayesian Reinforcement Learning framework using Relevant Vector Machines</h4>
				<div class="pubauthor"><strong>N. Tziortziotis</strong>,  K. Blekas</div>
				<div class="pubcite"><span class="label label-primary">Conference Paper</span> 25th International Conference on Artificial Inteligence (AAAI-2011), San Francinco, USA, August 2011.</div>

				
                              </div>
                              <div class="pubdetails">
				<p> In this work we present an advanced Bayesian formulation to the task of control learning that employs the Relevance Vector Machines (RVM) generative model for value function evaluation. The key aspect of the proposed method is the design of the discount return as a generative linear model that constitutes a well-known probabilistic approach. This allows to augment the model with advantegeous sparse priors provided by the RVM's regression framework. We have also taken into account the significant issue of selecting the proper parameters of the kernel design matrix. Experiments have shown that our method produces improved performance in both simulated and real test environments.</p>
                              </div>
                            </div>
			    
			  </div>
			</div>
		      </div>
		    </div>
		  </div>
		</div>
	      </div>
	    </div>

            <!--        <div id="teaching" class="page">
			<div class="pageheader">
			  <div class="headercontent">
                            <div class="section-container">
                              
                              <h2 class="title">Teaching</h2>
                              
                              <div class="row">
				<div class="col-md-12">
				  <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>                                                   
				</div>
                              </div>
                            </div>
			  </div>
			</div>
			<div class="pagecontents">
			  <div class="section color-1">
                            <div class="section-container">
                              <div class="row">
				<div class="title text-center">
				  <h3>Currrent Teaching</h3>
				</div>
				<ul class="ul-dates">
				  <li>
                                    <div class="dates">
                                      <span>Present</span>
                                      <span>1995</span>
                                    </div>
                                    <div class="content">
                                      <h4>Preclinical Endodnotics</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>Present</span>
                                      <span>2003</span>
                                    </div>
                                    <div class="content">
                                      <h4>SELC 8160 Molar Endodontic Selective</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>Present</span>
                                      <span>2010</span>
                                    </div>
                                    <div class="content">
                                      <h4>Endodontics Postdoctoral AEGD Program</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				</ul>
                              </div>
                            </div>
			  </div>
			  <div class="section color-2">
                            <div class="section-container">
                              <div class="row">
				<div class="title text-center">
				  <h3>Teaching History</h3>
				</div>
				<ul class="ul-dates-gray">
				  <li>
                                    <div class="dates">
                                      <span>1997</span>
                                      <span>1995</span>
                                    </div>
                                    <div class="content">
                                      <h4>Preclinical Endodnotics</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>2005</span>
                                      <span>2003</span>
                                    </div>
                                    <div class="content">
                                      <h4>SELC 8160 Molar Endodontic Selective</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>2011</span>
                                      <span>2010</span>
                                    </div>
                                    <div class="content">
                                      <h4>Endodontics Postdoctoral AEGD Program</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>2011</span>
                                      <span>2010</span>
                                    </div>
                                    <div class="content">
                                      <h4>Endodontics Postdoctoral AEGD Program</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				  <li>
                                    <div class="dates">
                                      <span>2011</span>
                                      <span>2010</span>
                                    </div>
                                    <div class="content">
                                      <h4>Endodontics Postdoctoral AEGD Program</h4>
                                      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                    </div>
				  </li>
				</ul>
                              </div>
                            </div>
			  </div>
			</div>
            </div> -->

	    <div id="usefullink" class="page">
              <div class="pageheader">
		<div class="headercontent">
		  <div class="section-container">
                    
                    <h2 class="title">Useful Links</h2>
                    
                    <div class="row">
                      <div class="col-md-12">
			<div class="subtitle text-left">
			  <h3>Software</h3>
			</div>
			<ul class="ul-boxed list-unstyled">
			  <li><a href="https://code.google.com/p/beliefbox/">Beliefbox Software</a></li>
			  <li><a href="http://www-all.cs.umass.edu/rlr/">Reinforcement Learning Repository, University of Massachusetts</a></li>
                          <li><a href="https://gym.openai.com/">OpenAI Gym</a></li>
			  <li><a href="http://glue.rl-community.org/wiki/Main_Page">RL-Glue</a></li>
			</ul>
			<div class="subtitle text-left">
			  <h3>Reinformement Learning Competition</h3>
			</div>
			I am a co-organizer of the of the revived RL Competition:
			<ul class="ul-boxed list-unstyled">
			  <li><a href="https://sites.google.com/site/rlcompetition2014/">Reinforcement Learning Competition 2014</a></li>
			  <li><a href="https://sites.google.com/site/rlcomp2013/icml_workshop">Reinforcement Learning Competition 2013 (ICML Workshop)</a></li>
			</ul>
			<div class="subtitle text-left">
			  <h3>Online Courses</h3>
			</div>
			<ul class="ul-boxed list-unstyled">
			  <li><a href="https://www.coursera.org/">Coursera</a></li>
			  <li><a href="http://ocw.mit.edu/courses/">MIT Open Course Ware</a></li>
			</ul>
                      </div>
                    </div>
		  </div>
		</div>
              </div>
	    </div>
            
            <div id="contact" class="page stellar">
              <div class="pageheader">
		<div class="headercontent">
		  <div class="section-container">
                    
                    <h2 class="title">Contact  Me</h2>
                    
                    <div class="row">
                      <!--     <div class="col-md-8">
                               <p>I would be happy to talk to you if you need my assistance in your research or whether you need bussiness administration support for your company. Though I have limited time for students but I Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>                              
                      </div> -->
                      <div class="col-md-10">
			<ul class="list-unstyled">
			  <!--<li>
                              <strong><i class="icon-phone"></i>&nbsp;&nbsp;</strong>
                              <span>mobile: +30-698-6698246</span>
			  </li>-->
			  <!-- <li>
                            <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                            <span>ntziortziotis@lix.polytechnique.fr</span>
			  </li> -->
			  <li>
                            <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                            <span>ntziorzi@gmail.com</span>
			  </li>
			  <li>
                            <strong><i class="icon-skype"></i>&nbsp;&nbsp;</strong>
                            <span>tzio_nick</span>
			  </li>
			  <!--    <li>
				  <strong><i class="icon-twitter"></i>&nbsp;&nbsp;</strong>
				  <span>#jenniferDoe</span>
			  </li>-->
			  <li>
                            <strong><i class="icon-linkedin-sign"></i>&nbsp;&nbsp;</strong>
                            <span><a href="#">gr.linkedin.com/pub/tziortziotis-nikolaos/43/401/604</a></span>
			  </li>
			</ul>    

                      </div>
                    </div>
		  </div>
		</div>
              </div>
              <div class="pagecontents">
		<!--    <div class="section contact-office" data-stellar-background-ratio="0.1">
			<div class="section-container">
			  <div class="row">
                            <div class="col-md-8">
                              <h2 class="title">At My Office</h2>
                              <p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                              <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                            </div>
                            <div class="col-md-4 text-center hidden-xs hidden-sm">
                              <i class="icon-coffee icon-huge"></i>
                            </div>

			  </div>
			</div>
		</div>
		<div class="section color-1">
		  <div class="section-container">
                    <div class="row">
                      <div class="col-md-4 text-center hidden-xs hidden-sm">
			<i class="icon-stethoscope icon-huge"></i>
                      </div>
                      <div class="col-md-8">
			<h2 class="title">At My Work</h2>
			<p>You can find me at my Work located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
			<p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                      </div>
                    </div>
		  </div>
		</div>
		<div class="section contact-lab" data-stellar-background-ratio="0.1">
		  <div class="section-container">
                    <div class="row">
                      
                      <div class="col-md-8">
			<h2 class="title">At My Lab</h2>
			<p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
			<p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                      </div>
                      <div class="col-md-4 text-center hidden-xs hidden-sm">
			<i class="icon-superscript icon-huge"></i>
                      </div>

                    </div>
		  </div>
		</div>
              </div> -->
              </div>
	    </div>
            
	    <div id="overlay"></div> 
            
	  </div>
	</div>
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','../../www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-45653136-1', 'owwwlab.com');
	  ga('send', 'pageview');

	</script>
  </body>
</html>
